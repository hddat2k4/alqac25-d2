{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:06.482521Z",
     "iopub.status.busy": "2025-07-03T05:07:06.482221Z",
     "iopub.status.idle": "2025-07-03T05:07:09.174150Z",
     "shell.execute_reply": "2025-07-03T05:07:09.173103Z",
     "shell.execute_reply.started": "2025-07-03T05:07:06.482507Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.29.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.176234Z",
     "iopub.status.busy": "2025-07-03T05:07:09.175990Z",
     "iopub.status.idle": "2025-07-03T05:07:09.184998Z",
     "shell.execute_reply": "2025-07-03T05:07:09.184060Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.176216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import time\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import itertools\n",
    "from google import genai\n",
    "from groq import Groq\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.185751Z",
     "iopub.status.busy": "2025-07-03T05:07:09.185496Z",
     "iopub.status.idle": "2025-07-03T05:07:09.202303Z",
     "shell.execute_reply": "2025-07-03T05:07:09.201223Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.185734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.204765Z",
     "iopub.status.busy": "2025-07-03T05:07:09.204491Z",
     "iopub.status.idle": "2025-07-03T05:07:09.282241Z",
     "shell.execute_reply": "2025-07-03T05:07:09.281585Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.204747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = load_json(\"/kaggle/input/evaluate-inference-model-alqac/alqac25_train.json\")         # danh sách câu hỏi\n",
    "law_data = load_json(\"/kaggle/input/evaluate-inference-model-alqac/alqac25_law.json\")       # ánh xạ article content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lấy nội dung của luật từ law_id và article_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.283389Z",
     "iopub.status.busy": "2025-07-03T05:07:09.283216Z",
     "iopub.status.idle": "2025-07-03T05:07:09.289911Z",
     "shell.execute_reply": "2025-07-03T05:07:09.289285Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.283376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "law_map = {}\n",
    "\n",
    "for law in law_data:\n",
    "    for article in law.get(\"articles\", []):\n",
    "        law_map[(law[\"id\"], article[\"id\"])] = article[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.291098Z",
     "iopub.status.busy": "2025-07-03T05:07:09.290910Z",
     "iopub.status.idle": "2025-07-03T05:07:09.308867Z",
     "shell.execute_reply": "2025-07-03T05:07:09.308101Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.291082Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_law_content(law_infors):\n",
    "    law_content = \"\"\n",
    "    for law_info in law_infors:\n",
    "        law_id = law_info['law_id']\n",
    "        article_id = law_info['article_id']\n",
    "        law_content += f\"Luật: {law_id}\" + '\\n' + law_map.get((law_id, article_id), \"\") + '\\n'*2\n",
    "    return law_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.309913Z",
     "iopub.status.busy": "2025-07-03T05:07:09.309649Z",
     "iopub.status.idle": "2025-07-03T05:07:09.322121Z",
     "shell.execute_reply": "2025-07-03T05:07:09.321404Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.309890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(get_law_content([\n",
    "#             {\n",
    "#                 \"law_id\": \"Luật Phòng, chống ma túy\",\n",
    "#                 \"article_id\": \"32\"\n",
    "#             }, \n",
    "#             {\n",
    "#                 \"law_id\": \"Luật Hôn nhân và gia đình\",\n",
    "#                 \"article_id\": \"3\"\n",
    "#             }\n",
    "#         ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thiết kế prompt cho từng loại câu hỏi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.322960Z",
     "iopub.status.busy": "2025-07-03T05:07:09.322783Z",
     "iopub.status.idle": "2025-07-03T05:07:09.339325Z",
     "shell.execute_reply": "2025-07-03T05:07:09.338621Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.322948Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prompt_design(question):\n",
    "    # Trích thông tin law_id và article_id (chỉ lấy phần tử đầu tiên trong danh sách relevant_articles)\n",
    "    law_infors = question['relevant_articles']\n",
    "\n",
    "    # Lấy nội dung điều luật\n",
    "    law_content = get_law_content(law_infors)\n",
    "\n",
    "    # Xử lý theo từng loại câu hỏi\n",
    "    if question['question_type'] == 'Đúng/Sai':\n",
    "        return (\n",
    "            f\"Hãy đọc điều luật dưới đây và trả lời câu hỏi Đúng/Sai bên dưới.\\n\\n\"\n",
    "            f\"Chỉ trả lời bằng MỘT từ duy nhất là \\\"Đúng\\\" hoặc \\\"Sai\\\".\\n\"\n",
    "            f\"KHÔNG được giải thích.\\n\"\n",
    "            f\"KHÔNG được ghi lại nội dung câu hỏi hoặc điều luật.\\n\"\n",
    "            f\"KHÔNG thêm bất kỳ nội dung nào khác ngoài một từ duy nhất: \\\"Đúng\\\" hoặc \\\"Sai\\\".\\n\\n\"\n",
    "            f\"Ví dụ:\\nCâu hỏi: …\\nTrả lời: Đúng\\n\\n\"\n",
    "            f\"Điều luật:\\n{law_content}\\n\\n\"\n",
    "            f\"Câu hỏi:\\n{question['text']}\\n\\n\"\n",
    "            f\"Trả lời:\"\n",
    "        )\n",
    "\n",
    "    elif question['question_type'] == 'Trắc nghiệm':\n",
    "        choices = question['choices']\n",
    "        return (\n",
    "            f\"Dựa vào điều luật sau, hãy trả lời câu hỏi trắc nghiệm dưới đây. \"\n",
    "            f\"Chọn duy nhất một đáp án đúng trong các lựa chọn A, B, C, D và TRẢ LỜI CHỈ BẰNG MỘT KÝ TỰ DUY NHẤT (A, B, C hoặc D), không thêm giải thích, không ghi lại nội dung đáp án.\\n\\n\"\n",
    "            f\"Ví dụ: Nếu đáp án là phương án A thì chỉ trả lời: A\\n\\n\"\n",
    "            f\"Điều luật:\\n{law_content}\\n\\n\"\n",
    "            f\"Câu hỏi:\\n{question['text']}\\n\\n\"\n",
    "            f\"Lựa chọn:\\n\"\n",
    "            f\"A. {choices['A']}\\n\"\n",
    "            f\"B. {choices['B']}\\n\"\n",
    "            f\"C. {choices['C']}\\n\"\n",
    "            f\"D. {choices['D']}\\n\\n\"\n",
    "            f\"Chỉ trả lời A, B, C hoặc D. Không ghi thêm gì khác.\\n\\n\"\n",
    "            f\"Đáp án:\"\n",
    "        )\n",
    "\n",
    "    else:  # Tự luận\n",
    "        return (\n",
    "            f\"Dựa vào điều luật sau, hãy trả lời câu hỏi dưới đây một cách chính xác và NGẮN GỌN.\\n\\n\"\n",
    "            f\"YÊU CẦU:\\n\"\n",
    "            f\"- Chỉ trích xuất đúng thông tin cần thiết từ điều luật.\\n\"\n",
    "            f\"- KHÔNG được lặp lại câu hỏi.\\n\"\n",
    "            f\"- KHÔNG thêm bất kỳ lời giải thích hay mở rộng nào.\\n\"\n",
    "            f\"- KHÔNG lặp lại nội dung điều luật.\\n\"\n",
    "            f\"- Câu trả lời chỉ bao gồm cụm từ hoặc con số trọng yếu (ví dụ: \\\"10 ngày\\\" hoặc \\\"3 cm x 4 cm\\\").\\n\\n\"\n",
    "            f\"Ví dụ:\\n\"\n",
    "            f\"- Câu hỏi: Thời hạn là bao lâu?\\n  → Trả lời: 10 ngày\\n\"\n",
    "            f\"- Câu hỏi: Kích thước ảnh bao nhiêu?\\n  → Trả lời: 3 cm x 4 cm\\n\\n\"\n",
    "            f\"Điều luật:\\n{law_content}\\n\\n\"\n",
    "            f\"Câu hỏi:\\n{question['text']}\\n\\n\"\n",
    "            f\"Trả lời:\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.340967Z",
     "iopub.status.busy": "2025-07-03T05:07:09.340620Z",
     "iopub.status.idle": "2025-07-03T05:07:09.360676Z",
     "shell.execute_reply": "2025-07-03T05:07:09.359886Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.340942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prompt_design_v2(question):\n",
    "    # Trích thông tin law_id và article_id (chỉ lấy phần tử đầu tiên trong danh sách relevant_articles)\n",
    "    law_infors = question['relevant_articles']\n",
    "\n",
    "    # Lấy nội dung điều luật\n",
    "    law_content = get_law_content(law_infors)\n",
    "\n",
    "    # Xử lý theo từng loại câu hỏi\n",
    "    if question['question_type'] == 'Đúng/Sai':\n",
    "        return (\n",
    "            f\"Bạn là một chuyên gia trả lời câu hỏi nhận định đúng/sai pháp luật.\"\n",
    "            f\"Dựa vào điều luật được cung cấp, hãy xác định xem nhận định trong câu hỏi dưới đây là Đúng hay Sai.\\n\\n\"\n",
    "            f\"**YÊU CẦU BẮT BUỘC:**\\n\"\n",
    "            f\"Câu trả lời của bạn CHỈ ĐƯỢC PHÉP là MỘT trong hai từ sau: \\\"Đúng\\\" hoặc \\\"Sai\\\".\\n\\n\"\n",
    "            f\"--- BẮT ĐẦU DỮ LIỆU ---\\n\\n\"\n",
    "            f\"**Điều luật:**\\n{law_content}\\n\\n\"\n",
    "            f\"**Câu hỏi:**\\n{question['text']}\\n\\n\"\n",
    "            f\"--- KẾT THÚC DỮ LIỆU ---\\n\\n\"\n",
    "            f\"**Nhận định trên là (chỉ điền Đúng hoặc Sai):**\"  # Thay \"Trả lời:\" bằng một câu hỏi đóng hơn\n",
    "        )\n",
    "\n",
    "    elif question['question_type'] == 'Trắc nghiệm':\n",
    "        choices = question['choices']\n",
    "        return (\n",
    "            f\"Bạn là một chuyên gia trả lời câu hỏi trắc nghiệm pháp luật. Nhiệm vụ của bạn là đọc kỹ điều luật và câu hỏi, sau đó chọn một đáp án duy nhất (A, B, C, hoặc D).\\n\\n\"\n",
    "            f\"**YÊU CẦU BẮT BUỘC:** Câu trả lời cuối cùng của bạn phải là MỘT KÝ TỰ DUY NHẤT.\\n\\n\"\n",
    "            f\"--- Bối cảnh ---\\n\"\n",
    "            f\"Điều luật: {law_content}\\n\\n\"\n",
    "            f\"--- Câu hỏi và Lựa chọn ---\\n\"\n",
    "            f\"Câu hỏi: {question['text']}\\n\"\n",
    "            f\"A. {choices['A']}\\n\"\n",
    "            f\"B. {choices['B']}\\n\"\n",
    "            f\"C. {choices['C']}\\n\"\n",
    "            f\"D. {choices['D']}\\n\\n\"\n",
    "            f\"--- Đáp án ---\\n\"\n",
    "            f\"Lựa chọn chính xác nhất là (chỉ ghi A, B, C, hoặc D):\" # Tín hiệu kết thúc mạnh mẽ và rõ ràng\n",
    "        )\n",
    "\n",
    "    else: # Tự luận\n",
    "        return (\n",
    "            f\"Bạn là một trợ lý pháp lý chuyên trích xuất thông tin. Nhiệm vụ của bạn là đọc điều luật được cung cấp và trả lời câu hỏi một cách ngắn gọn, chính xác.\\n\\n\"\n",
    "            f\"### YÊU CẦU NGHIÊM NGẶT:\\n\"\n",
    "            f\"1. Chỉ trích xuất phần nội dung trả lời trực tiếp cho câu hỏi trong điều luật.\\n\"\n",
    "            f\"2. KHÔNG được sao chép toàn bộ đoạn luật, chỉ lấy phần có ý nghĩa trả lời.\\n\"\n",
    "            f\"3. KHÔNG được viết lại câu hỏi, không được thêm giải thích hoặc bình luận.\\n\"\n",
    "            f\"4. Câu trả lời phải ngắn gọn, đầy đủ ý và đúng theo điều luật.\\n\\n\"\n",
    "            f\"<DỮ LIỆU>\\n\"\n",
    "            f\"Điều luật:\\n{law_content}\\n\\n\"\n",
    "            f\"Câu hỏi:\\n{question['text']}\\n\\n\"\n",
    "            f\"<Câu trả lời (chỉ một câu ngắn, không dài dòng, không lặp lại thông tin)> \\n\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sử dụng LLM để trả lời câu hỏi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.363742Z",
     "iopub.status.busy": "2025-07-03T05:07:09.363550Z",
     "iopub.status.idle": "2025-07-03T05:07:09.378582Z",
     "shell.execute_reply": "2025-07-03T05:07:09.377887Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.363730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_answer(model, tokenizer, question):\n",
    "    input_text = prompt_design_v2(question)\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Thiết lập cấu hình tùy theo loại câu hỏi\n",
    "    qtype = question['question_type']\n",
    "\n",
    "    if qtype == \"Đúng/Sai\":\n",
    "        do_sample = False\n",
    "        max_new_tokens = 3  # Đủ để sinh ra \"Đúng\" hoặc \"Sai\"\n",
    "\n",
    "    elif qtype == \"Trắc nghiệm\":\n",
    "        do_sample = False\n",
    "        max_new_tokens = 3  # Đủ để sinh ra \"A\", \"B\", \"C\", \"D\"\n",
    "\n",
    "    else:\n",
    "        do_sample = False # Có thể để True nếu cần sinh ra câu trả lời đa dạng\n",
    "        max_new_tokens = 128  # Đủ dài để trả lời ngắn gọn nhưng đầy đủ\n",
    "        \n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=do_sample,\n",
    "            temperature=0.1 if do_sample else 1.0,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode only the generated part (exclude input)\n",
    "    generated_tokens = outputs[0][inputs['input_ids'].shape[1]:]\n",
    "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tải mô hình và tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.379465Z",
     "iopub.status.busy": "2025-07-03T05:07:09.379267Z",
     "iopub.status.idle": "2025-07-03T05:07:09.394732Z",
     "shell.execute_reply": "2025-07-03T05:07:09.394179Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.379448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"google/gemma-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.395541Z",
     "iopub.status.busy": "2025-07-03T05:07:09.395357Z",
     "iopub.status.idle": "2025-07-03T05:07:09.407181Z",
     "shell.execute_reply": "2025-07-03T05:07:09.406494Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.395526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Load model and tokenizer\n",
    "# from huggingface_hub import login\n",
    "\n",
    "\n",
    "# print(f\"Loading {model_name} model...\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     model_name,\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "#     device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "#     trust_remote_code=True,\n",
    "#     use_cache=True\n",
    "# )\n",
    "\n",
    "# # Set pad token if not exists\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# print(\"Model loaded successfully!\")\n",
    "# print(f\"Model device: {model.device}\")\n",
    "# print(f\"Model dtype: {model.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng pipeline đánh giá model từ train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.408088Z",
     "iopub.status.busy": "2025-07-03T05:07:09.407809Z",
     "iopub.status.idle": "2025-07-03T05:07:09.425749Z",
     "shell.execute_reply": "2025-07-03T05:07:09.425101Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.408070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_pipeline(model, tokenizer):\n",
    "    results = []\n",
    "    for question in tqdm(train_data, desc=\"Processing and Evaluating questions\"):\n",
    "        # if question['question_type'] == \"Trắc nghiệm\": # Test\n",
    "            try:\n",
    "                # 1. Dự đoán từ mô hình của bạn\n",
    "                pred_answer = predict_answer(model, tokenizer, question)\n",
    "                ground_truth_answer = question.get(\"answer\", None)\n",
    "    \n",
    "                # # 2. Đánh giá Đúng/Sai bằng API\n",
    "                # evaluation_result = get_binary_evaluation(pred_answer, ground_truth_answer)\n",
    "                \n",
    "                # 3. Ghi kết quả\n",
    "                results.append({\n",
    "                    \"question_id\": question[\"question_id\"],\n",
    "                    \"question\": question[\"text\"],\n",
    "                    \"question_type\": question[\"question_type\"],\n",
    "                    \"predicted_answer\": pred_answer,\n",
    "                    \"ground_truth_answer\": ground_truth_answer,\n",
    "                    # \"evaluation\": evaluation_result\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi trong pipeline với câu hỏi {question.get('question_id', 'unknown')}: {str(e)}\")\n",
    "                results.append({\n",
    "                    \"question_id\": question.get(\"question_id\", \"unknown\"),\n",
    "                    \"question\": question[\"text\"],\n",
    "                    \"question_type\": question[\"question_type\"],\n",
    "                    \"predicted_answer\": \"ERROR\",\n",
    "                    \"ground_truth_answer\": question.get(\"answer\", None),\n",
    "                    # \"evaluation\": \"Lỗi_pipeline\"\n",
    "                })\n",
    "            # break # Test\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.427096Z",
     "iopub.status.busy": "2025-07-03T05:07:09.426892Z",
     "iopub.status.idle": "2025-07-03T05:07:09.441454Z",
     "shell.execute_reply": "2025-07-03T05:07:09.440780Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.427084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Run the pipeline\n",
    "# print(\"Starting evaluation pipeline...\")\n",
    "# final_results = run_pipeline(model, tokenizer)\n",
    "\n",
    "# # Save results\n",
    "# output_file = f\"{model_name.split('/')[-1]}_results.json\"\n",
    "# with open(output_file, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(final_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# print(f\"Evaluation completed! Results saved to {output_file}\")\n",
    "# print(f\"Total questions processed: {len(final_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.442361Z",
     "iopub.status.busy": "2025-07-03T05:07:09.442182Z",
     "iopub.status.idle": "2025-07-03T05:07:09.458748Z",
     "shell.execute_reply": "2025-07-03T05:07:09.458091Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.442346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Print some sample results\n",
    "# print(\"\\nSample results:\")\n",
    "# for i, result in enumerate(final_results[:3]):\n",
    "#     print(f\"\\nQuestion {i+1}:\")\n",
    "#     print(f\"Type: {result['question_type']}\")\n",
    "#     print(f\"Question: {result['question'][:100]}...\")\n",
    "#     print(f\"Predicted: {result['predicted_answer']}\")\n",
    "#     print(f\"Ground Truth: {result['ground_truth_answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gọi API Gemini và Groq để đánh giá kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.459651Z",
     "iopub.status.busy": "2025-07-03T05:07:09.459432Z",
     "iopub.status.idle": "2025-07-03T05:07:09.473318Z",
     "shell.execute_reply": "2025-07-03T05:07:09.472585Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.459633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lấy API key\n",
    "user_secrets = UserSecretsClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:09.474304Z",
     "iopub.status.busy": "2025-07-03T05:07:09.474140Z",
     "iopub.status.idle": "2025-07-03T05:07:10.050782Z",
     "shell.execute_reply": "2025-07-03T05:07:10.050120Z",
     "shell.execute_reply.started": "2025-07-03T05:07:09.474290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gemini_keys = [\n",
    "    user_secrets.get_secret(f\"GEMINI_API_KEY_{i}\") for i in range(1, 4)\n",
    "]\n",
    "\n",
    "gemini_cycle = itertools.cycle(gemini_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.052264Z",
     "iopub.status.busy": "2025-07-03T05:07:10.051939Z",
     "iopub.status.idle": "2025-07-03T05:07:10.055573Z",
     "shell.execute_reply": "2025-07-03T05:07:10.055000Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.052246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_next_gemini_key():\n",
    "    return next(gemini_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.056315Z",
     "iopub.status.busy": "2025-07-03T05:07:10.056136Z",
     "iopub.status.idle": "2025-07-03T05:07:10.072475Z",
     "shell.execute_reply": "2025-07-03T05:07:10.071756Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.056300Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def call_gemini(prompt, api_key):\n",
    "    client_gemini = genai.Client(api_key = api_key) \n",
    "    response = client_gemini.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\", \n",
    "            contents=prompt\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.073823Z",
     "iopub.status.busy": "2025-07-03T05:07:10.073599Z",
     "iopub.status.idle": "2025-07-03T05:07:10.086826Z",
     "shell.execute_reply": "2025-07-03T05:07:10.086155Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.073804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(call_gemini(\"Trường Đại học Công Nghệ Thông tin?\", get_next_gemini_key()).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.087822Z",
     "iopub.status.busy": "2025-07-03T05:07:10.087609Z",
     "iopub.status.idle": "2025-07-03T05:07:10.678487Z",
     "shell.execute_reply": "2025-07-03T05:07:10.677857Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.087804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "groq_keys = [\n",
    "    user_secrets.get_secret(f\"GROQ_API_KEY_{i}\") for i in range(1, 4)\n",
    "]\n",
    "\n",
    "groq_cycle = itertools.cycle(groq_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.679423Z",
     "iopub.status.busy": "2025-07-03T05:07:10.679243Z",
     "iopub.status.idle": "2025-07-03T05:07:10.683017Z",
     "shell.execute_reply": "2025-07-03T05:07:10.682365Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.679410Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_next_groq_key():\n",
    "    return next(groq_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.684325Z",
     "iopub.status.busy": "2025-07-03T05:07:10.683869Z",
     "iopub.status.idle": "2025-07-03T05:07:10.699051Z",
     "shell.execute_reply": "2025-07-03T05:07:10.698188Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.684301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def call_groq(prompt, api_key):\n",
    "    client_groq = Groq(\n",
    "        api_key=api_key,\n",
    "    )\n",
    "    \n",
    "    chat_completion = client_groq.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"qwen/qwen3-32b\",\n",
    "    )\n",
    "    \n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.700258Z",
     "iopub.status.busy": "2025-07-03T05:07:10.700042Z",
     "iopub.status.idle": "2025-07-03T05:07:10.712353Z",
     "shell.execute_reply": "2025-07-03T05:07:10.711488Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.700241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(call_groq(\"Trường Đại học Công Nghệ Thông tin?\", get_next_groq_key()).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt để đánh giá kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.713526Z",
     "iopub.status.busy": "2025-07-03T05:07:10.713249Z",
     "iopub.status.idle": "2025-07-03T05:07:10.729402Z",
     "shell.execute_reply": "2025-07-03T05:07:10.728738Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.713505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- ĐỊNH NGHĨA PROMPT ---\n",
    "EVALUATION_PROMPT_TEMPLATE = \"\"\"**Bối cảnh:** Bạn là một giám khảo cực kỳ nghiêm khắc. Nhiệm vụ của bạn là so sánh \"Câu trả lời dự đoán\" và \"Câu trả lời đúng (Ground Truth)\".\n",
    "\n",
    "**Quy tắc:**\n",
    "- Nếu \"Câu trả lời dự đoán\" có cùng ý nghĩa hoặc tương đương về mặt ngữ nghĩa với \"Câu trả lời đúng\", hãy coi nó là **Đúng**.\n",
    "- Nếu \"Câu trả lời dự đoán\" sai về mặt thông tin, hoặc thiếu thông tin cốt lõi, hãy coi nó là **Sai**.\n",
    "\n",
    "**Yêu cầu về định dạng đầu ra:**\n",
    "TUYỆT ĐỐI chỉ trả lời MỘT TỪ DUY NHẤT: **Đúng** hoặc **Sai**.\n",
    "KHÔNG giải thích. KHÔNG thêm bất kỳ văn bản hay ký tự nào khác.\n",
    "\n",
    "---\n",
    "**VÍ DỤ 1:**\n",
    "**Câu trả lời dự đoán:** Hồ sơ đề nghị cấp lại thẻ hướng dẫn viên du lịch bao gồm ảnh chân dung màu cỡ 3 cm x 4 cm.\n",
    "**Câu trả lời đúng (Ground Truth):** 3 cm x 4 cm.\n",
    "**Đánh giá:**\n",
    "Đúng\n",
    "\n",
    "---\n",
    "**VÍ DỤ 2:**\n",
    "**Câu trả lời dự đoán:** Lừa dối, đe dọa, cưỡng ép, mua chuộc, sử dụng vũ lực nhằm ngăn cản người phiên dịch thực hiện nhiệm vụ hoặc buộc người phiên dịch dịch không trung thực, không khách quan, không đúng nghĩa..\n",
    "**Câu trả lời đúng (Ground Truth):** Dịch sai sự thật.\n",
    "**Đánh giá:**\n",
    "Sai\n",
    "\n",
    "---\n",
    "**YÊU CẦU ĐÁNH GIÁ:**\n",
    "**Câu trả lời dự đoán:**\n",
    "{predicted_answer}\n",
    "\n",
    "**Câu trả lời đúng (Ground Truth):**\n",
    "{ground_truth_answer}\n",
    "\n",
    "**Đánh giá:**\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So sánh Predict Answer và Ground Truth Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dùng Regex cho câu hỏi Đúng/Sai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.730313Z",
     "iopub.status.busy": "2025-07-03T05:07:10.730129Z",
     "iopub.status.idle": "2025-07-03T05:07:10.743357Z",
     "shell.execute_reply": "2025-07-03T05:07:10.742665Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.730299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def check_true_false(predicted, ground_truth):\n",
    "    # Tìm tất cả các từ \"Đúng\" hoặc \"Sai\"\n",
    "    matches = re.findall(r'\\b(Đúng|Sai)\\b', predicted, re.IGNORECASE)\n",
    "    matches = [m.capitalize() for m in matches]\n",
    "    matches_set = set(matches)\n",
    "\n",
    "    # Không có câu trả lời hợp lệ\n",
    "    if not matches_set:\n",
    "        return 0\n",
    "\n",
    "    # Có cả Đúng và Sai cùng lúc ⇒ sai ngay\n",
    "    if 'Đúng' in matches_set and 'Sai' in matches_set:\n",
    "        return 0\n",
    "\n",
    "    # Nếu chỉ có một trong hai và khớp ground_truth ⇒ đúng\n",
    "    if ground_truth in matches_set:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.744155Z",
     "iopub.status.busy": "2025-07-03T05:07:10.743987Z",
     "iopub.status.idle": "2025-07-03T05:07:10.762750Z",
     "shell.execute_reply": "2025-07-03T05:07:10.761715Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.744144Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(check_true_false(\"Sai\\n\\n---\", \"Sai\"))\n",
    "print(check_true_false(\"Đúng\", \"Đúng\"))\n",
    "print(check_true_false(\"Sai\\n\\n---\", \"Đúng\"))\n",
    "print(check_true_false(\"Đúng\", \"Sai\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dùng Regex cho câu hỏi Trắc nghiệm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.766147Z",
     "iopub.status.busy": "2025-07-03T05:07:10.765911Z",
     "iopub.status.idle": "2025-07-03T05:07:10.776432Z",
     "shell.execute_reply": "2025-07-03T05:07:10.775623Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.766131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def check_multiple_choice(predicted, ground_truth):\n",
    "    # Kiểm tra có ít nhất một ký tự A, B, C, D hay không\n",
    "    if not re.search(r'\\b[A-D]\\b', predicted, re.IGNORECASE):\n",
    "        return 0\n",
    "\n",
    "    # Duyệt từ trái sang phải để tìm ký tự đầu tiên A-D\n",
    "    for ch in predicted.upper():\n",
    "        if ch in {'A', 'B', 'C', 'D'}:\n",
    "            return 1 if ch == ground_truth.upper() else 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.777470Z",
     "iopub.status.busy": "2025-07-03T05:07:10.777216Z",
     "iopub.status.idle": "2025-07-03T05:07:10.790723Z",
     "shell.execute_reply": "2025-07-03T05:07:10.789899Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.777449Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(check_multiple_choice(\"A\\n\\n---\", \"A\"))\n",
    "print(check_multiple_choice(\"C\\nC\", \"C\"))\n",
    "print(check_multiple_choice(\"A\\n\\n---\", \"A\"))\n",
    "print(check_multiple_choice(\"A\\n\\nA\", \"B\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gọi API cho câu hỏi tự luận"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.791783Z",
     "iopub.status.busy": "2025-07-03T05:07:10.791566Z",
     "iopub.status.idle": "2025-07-03T05:07:10.804020Z",
     "shell.execute_reply": "2025-07-03T05:07:10.803340Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.791763Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def check_free_text(pred_answer, ground_truth_answer, i):\n",
    "    \"\"\"\n",
    "    Sử dụng Gemini/Groq để trả về 'Đúng' hoặc 'Sai'.\n",
    "    \"\"\"\n",
    "    if not pred_answer or not ground_truth_answer:\n",
    "        return 0  # Lỗi đầu vào coi là sai\n",
    "\n",
    "    prompt = EVALUATION_PROMPT_TEMPLATE.format(\n",
    "        predicted_answer=pred_answer,\n",
    "        ground_truth_answer=ground_truth_answer\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        if i % 2 == 0:\n",
    "            response = call_gemini(prompt, get_next_gemini_key())\n",
    "        else:\n",
    "            response = call_groq(prompt, get_next_groq_key())\n",
    "        \n",
    "        result_text = response.strip()\n",
    "\n",
    "        # Chuẩn hóa kết quả\n",
    "        if result_text == \"Đúng\":\n",
    "            return 1\n",
    "        elif result_text == \"Sai\":\n",
    "            return 0\n",
    "        else:\n",
    "            # Trường hợp Gemini/Groq trả về không sạch ⇒ fallback\n",
    "            print(f\"Warning: Gemini/Groq response unclear\")\n",
    "            if \"Đúng\" in result_text:\n",
    "                return 1\n",
    "            elif \"Sai\" in result_text:\n",
    "                return 0\n",
    "            else:\n",
    "                return 0  # Không xác định ⇒ mặc định sai\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi gọi API: {str(e)}\")\n",
    "        time.sleep(1)\n",
    "        return 0  # Lỗi hệ thống ⇒ mặc định sai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:10.805006Z",
     "iopub.status.busy": "2025-07-03T05:07:10.804783Z",
     "iopub.status.idle": "2025-07-03T05:07:15.788919Z",
     "shell.execute_reply": "2025-07-03T05:07:15.788005Z",
     "shell.execute_reply.started": "2025-07-03T05:07:10.804992Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(check_free_text(\n",
    "    \"Thông tin thuộc bí mật nhà nước được tiếp cận khi được giải mật theo quy định của Luật này.\\nDựa trên điều luật, thông tin thuộc bí mật nhà nước được tiếp cận khi được giải mật theo quy định của Luật Tiếp cận thông tin. \\n\\n(Câu trả lời đã tuân thủ yêu cầu, ngắn gọn và chính xác)\",\n",
    "    \"được giải mật\",\n",
    "    0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đánh giá bằng API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T05:07:15.789975Z",
     "iopub.status.busy": "2025-07-03T05:07:15.789766Z",
     "iopub.status.idle": "2025-07-03T05:07:15.796386Z",
     "shell.execute_reply": "2025-07-03T05:07:15.795302Z",
     "shell.execute_reply.started": "2025-07-03T05:07:15.789960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(file_path, output_path):\n",
    "    with open(file_path, \"r\", encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    correct_list = []\n",
    "    total = len(data)\n",
    "\n",
    "    print(f\"Tổng số câu hỏi: {total}\")\n",
    "\n",
    "    for i, item in enumerate(data):\n",
    "        qtype = item.get('question_type', '').strip()\n",
    "        pred = item.get('predicted_answer', '').strip()\n",
    "        gt = item.get('ground_truth_answer', '').strip()\n",
    "\n",
    "        if qtype == 'Đúng/Sai':\n",
    "            is_true = check_true_false(pred, gt)\n",
    "        elif qtype == 'Trắc nghiệm':\n",
    "            is_true = check_multiple_choice(pred, gt)\n",
    "        elif qtype == 'Tự luận':\n",
    "            is_true = check_free_text(pred, gt, i)\n",
    "            \n",
    "        else:\n",
    "            is_true = 0  # Unknown question type\n",
    "\n",
    "        item['is_True'] = is_true\n",
    "        correct_list.append(is_true)\n",
    "\n",
    "    accuracy = sum(correct_list) / total if total > 0 else 0\n",
    "    \n",
    "    print(f\"Accuracy tổng thể: {accuracy:.2%}\")\n",
    "    \n",
    "    with open(output_path, \"w\", encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Kết quả đã lưu vào: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T06:34:37.357976Z",
     "iopub.status.busy": "2025-07-03T06:34:37.357692Z",
     "iopub.status.idle": "2025-07-03T06:34:37.362836Z",
     "shell.execute_reply": "2025-07-03T06:34:37.361904Z",
     "shell.execute_reply.started": "2025-07-03T06:34:37.357958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Llama-3.1-8B-Instruct_results_CHECK.json\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/kaggle/input/model-results/inference_result/Llama-3.1-8B-Instruct_results.json\" \n",
    "file_name = file_path.split('/')[-1]\n",
    "output_path = f\"/kaggle/working/{file_name[:-5]}_CHECK.json\"\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T06:34:39.837686Z",
     "iopub.status.busy": "2025-07-03T06:34:39.837423Z",
     "iopub.status.idle": "2025-07-03T06:38:10.559594Z",
     "shell.execute_reply": "2025-07-03T06:38:10.558906Z",
     "shell.execute_reply.started": "2025-07-03T06:34:39.837668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số câu hỏi: 729\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Warning: Gemini/Groq response unclear\n",
      "Accuracy tổng thể: 73.80%\n",
      "Kết quả đã lưu vào: /kaggle/working/Llama-3.1-8B-Instruct_results_CHECK.json\n"
     ]
    }
   ],
   "source": [
    "evaluate_accuracy(file_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7762836,
     "sourceId": 12315776,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7790807,
     "sourceId": 12358361,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
